{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from numpy.random import seed\n",
    "seed(1) #this is for fixing the random values\n",
    "from tensorflow import set_random_seed #this is for fixing the random values\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''' Here the things that we are going to do in this script:\n",
    "1. Define your graph:\n",
    "      a) Create Convolutional Layers.\n",
    "      b) Create Fully-connected and Flatten Layers\n",
    "      c) Create Other optimizer, loss function and others\n",
    "2. Prepare your input dataset for training. \n",
    "3. Evaluating your own results. \n",
    "''' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us firstly now try to read and format the data according to our requirement.....\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. \n",
    "\n",
    "The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. \n",
    "\n",
    "Between them, the training batches contain exactly 5000 images from each class.\n",
    "#### We are going to use batch 1-4 as training dataset, batch 5 as validation dataset and test batch for testing\n",
    "The Cifar-10 dataset downloaded is in the pickle format of python, so firstly we need to unpickle it using the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'filenames' 10000\n",
      "b'batch_label' 10000\n",
      "b'data' 10000\n",
      "b'labels' 10000\n"
     ]
    }
   ],
   "source": [
    "train_batch_1=unpickle('data_batch_1')\n",
    "train_batch_2=unpickle('data_batch_2')\n",
    "train_batch_3=unpickle('data_batch_3')\n",
    "train_batch_4=unpickle('data_batch_4')\n",
    "val_batch=unpickle('data_batch_5')\n",
    "test_batch=unpickle('test_batch')\n",
    "\n",
    "for key in train_batch_1:\n",
    "    print(key,len(train_batch_1[b'data']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below function converts key of the dictonary from bytes to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    if isinstance(data, bytes):  return data.decode('ascii')\n",
    "    if isinstance(data, dict):   return dict(map(convert, data.items()))\n",
    "    if isinstance(data, tuple):  return map(convert, data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_1=convert(train_batch_1)\n",
    "train_batch_2=convert(train_batch_2)\n",
    "train_batch_3=convert(train_batch_3)\n",
    "train_batch_4=convert(train_batch_4)\n",
    "val_batch=convert(val_batch)\n",
    "test_batch=convert(test_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separation of the Data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_Data=np.concatenate((train_batch_1['data'],train_batch_2['data'],train_batch_3['data'],train_batch_4['data']),axis=0).astype(np.float32)\n",
    "train_Labels=np.concatenate((train_batch_1['labels'],train_batch_2['labels'],train_batch_3['labels'],train_batch_4['labels']),axis=0).astype(np.float32)\n",
    "val_data=np.array(val_batch['data']).astype(np.float32)\n",
    "val_label=np.array(val_batch['labels']).astype(np.float32)\n",
    "test_data=np.array(test_batch['data']).astype(np.float32)\n",
    "test_label=np.array(test_batch['labels']).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_format_changer(labels):\n",
    "    label_changed=np.zeros((labels.shape[0],10))    \n",
    "    for i in range(labels.shape[0]):\n",
    "           label_changed[i][int(labels[i])]=1.0\n",
    "    return label_changed   \n",
    "\n",
    "train_Labels=label_format_changer(train_Labels)\n",
    "val_label=label_format_changer(val_label)\n",
    "test_label=label_format_changer(test_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping of the Data in to Images of 40000x32x32x3 for training  \n",
    "Reshaping of the Data in to Images of 10000x32x32x3 for validation  \n",
    "Reshaping of the Data in to Images of 10000x32x32x3 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_Data = train_Data.reshape(40000,3,32,32).transpose(0,2,3,1)\n",
    "val_data = val_data.reshape(10000,3,32,32).transpose(0,2,3,1)\n",
    "test_data = test_data.reshape(10000,3,32,32).transpose(0,2,3,1)\n",
    "#print(train_Data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DatasetHandler():\n",
    "    def __init__(self, images, labels):\n",
    "        self._num_examples = images.shape[0]\n",
    "        self._images = images\n",
    "        self._labels = labels\n",
    "        self._epochs_done = 0\n",
    "        self._index_in_epoch = 0\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "          # After each epoch we update this\n",
    "            self._epochs_done += 1\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "        #print(self._index_in_epoch)\n",
    "\n",
    "        return self._images[start:end], self._labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=50\n",
    "img_size=32\n",
    "num_channels=3\n",
    "number_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session=tf.Session()\n",
    "x=tf.placeholder(tf.float32,[None,img_size,img_size,num_channels])\n",
    "\n",
    "#labels\n",
    "y_true=tf.placeholder(tf.float32,[None,number_classes])\n",
    "y_true_cls=tf.argmax(y_true,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Graph Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_size_conv1=5\n",
    "num_filters_conv1=6\n",
    "\n",
    "filter_size_conv2=5\n",
    "num_filters_conv2=10\n",
    "\n",
    "fc_layer_1_size=120\n",
    "fc_layer_2_size=84\n",
    "fc_last_layer=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape,stddev=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_biases(size):\n",
    "    return tf.Variable(tf.constant(0.05,shape=[size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_convolutional_layer(input,\n",
    "                        num_input_channels,\n",
    "                        conv_filter_size,\n",
    "                        num_filters):\n",
    "    # we shall define the weights that will be trained using create_weights function\n",
    "    weights=create_weights(shape=[conv_filter_size,conv_filter_size,num_input_channels,num_filters])\n",
    "    ## We create biases using the create_biases function. These are also trained\n",
    "    biases=create_biases(num_filters)\n",
    "    \n",
    "    ## Creating the convolutional layer\n",
    "    layer=tf.nn.conv2d(input=input,\n",
    "                       filter=weights,\n",
    "                       strides=[1,1,1,1],\n",
    "                       padding='SAME')\n",
    "    layer+=biases\n",
    "    #order of relu and maxpooling doesn't matter in terms of answer, but it matters in computational efficiency\n",
    "    #max-pooling-> relu is more time effiecient\n",
    "    #We shall be using max-pooling\n",
    "    layer=tf.nn.max_pool(value=layer,\n",
    "                         ksize=[1,2,2,1],\n",
    "                         strides=[1,2,2,1],\n",
    "                         padding='SAME')\n",
    "    ## output of pooling is fed to Relu which is the activation function for us\n",
    "    layer=tf.nn.relu(layer)\n",
    "    return layer\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_flatten_layer(layer):\n",
    "    #we know that the shape of the layer will be  [batch_size img_size img_size num_channels]\n",
    "    #but lets's get it from the previous layer\n",
    "    layer_shape=layer.get_shape()\n",
    "    print(layer_shape)\n",
    "     ## Number of features will be img_height * img_width* num_channels. But we shall calculate it in place of hard-coding it.\n",
    "    num_features=layer_shape[1:4].num_elements()\n",
    "    \n",
    "    ##Now, we Flatten the layer so we shall have to reshape to num_features\n",
    "    layer=tf.reshape(layer,[-1,num_features])\n",
    "    print('shape of the flat layer')\n",
    "    print(layer.shape)\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fc_layer(input,\n",
    "                    num_input,\n",
    "                    num_outputs,\n",
    "                    use_relu=True):\n",
    "    #Let's define trainable weights and biases\n",
    "    weights=create_weights(shape=[num_input,num_outputs])\n",
    "    biases=create_biases(num_outputs)\n",
    "    \n",
    "    #Fully Connected layer takes input x and produces wx+b.since, these are matrices, we use matmul function in Tensorflow\n",
    "    layer=tf.matmul(input,weights)+biases\n",
    "    if use_relu:\n",
    "        layer=tf.nn.relu(layer)\n",
    "    print('shape of the fully connected layer')\n",
    "    print(layer.shape)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 8, 8, 10)\n",
      "shape of the flat layer\n",
      "(?, 640)\n",
      "shape of the fully connected layer\n",
      "(?, 120)\n",
      "shape of the fully connected layer\n",
      "(?, 84)\n",
      "shape of the fully connected layer\n",
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "layer_conv1=create_convolutional_layer(input=x,\n",
    "                                      num_input_channels=num_channels,\n",
    "                                      conv_filter_size=filter_size_conv1,\n",
    "                                      num_filters=num_filters_conv1)\n",
    "\n",
    "layer_conv2=create_convolutional_layer(input=layer_conv1,\n",
    "                                      num_input_channels=num_filters_conv1,\n",
    "                                      conv_filter_size=filter_size_conv2,\n",
    "                                      num_filters=num_filters_conv2)\n",
    "\n",
    "layer_flat=create_flatten_layer(layer_conv2)\n",
    "\n",
    "layer_fc1=create_fc_layer(input=layer_flat,\n",
    "                         num_input=layer_flat.get_shape()[1:4].num_elements(),\n",
    "                         num_outputs=fc_layer_1_size,\n",
    "                         use_relu=True)\n",
    "\n",
    "\n",
    "layer_fc2=create_fc_layer(input=layer_fc1,\n",
    "                         num_input=fc_layer_1_size,\n",
    "                         num_outputs=fc_layer_2_size,\n",
    "                         use_relu=True)\n",
    "\n",
    "\n",
    "layer_fc3=create_fc_layer(input=layer_fc2,\n",
    "                         num_input=fc_layer_2_size,\n",
    "                         num_outputs=number_classes,\n",
    "                         use_relu=False)\n",
    "y_pred=tf.nn.softmax(layer_fc3,name='y_pred')\n",
    "\n",
    "y_pred_cls=tf.argmax(y_pred,axis=1)\n",
    "\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "cross_entropy=tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc3,\n",
    "                                                         labels=y_true)\n",
    "\n",
    "cost=tf.reduce_mean(cross_entropy)\n",
    "\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "correct_prediction=tf.equal(y_pred_cls,y_true_cls)\n",
    "\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_progress(epoch, feed_dict_train, feed_dict_validate, val_loss):\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "    val_acc = session.run(accuracy, feed_dict=feed_dict_validate)\n",
    "    msg = \"Training Epoch {0} --- Training Accuracy: {1:>6.1%}, Validation Accuracy: {2:>6.1%},  Validation Loss: {3:.3f}\"\n",
    "    print(msg.format(epoch + 1, acc, val_acc, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_iterations = 0\n",
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 2 --- Training Accuracy:  52.0%, Validation Accuracy:  42.0%,  Validation Loss: 1.635\n",
      "Training Epoch 3 --- Training Accuracy:  52.0%, Validation Accuracy:  47.0%,  Validation Loss: 1.503\n",
      "Training Epoch 4 --- Training Accuracy:  58.0%, Validation Accuracy:  50.2%,  Validation Loss: 1.419\n",
      "Training Epoch 5 --- Training Accuracy:  58.0%, Validation Accuracy:  51.7%,  Validation Loss: 1.373\n",
      "Training Epoch 6 --- Training Accuracy:  60.0%, Validation Accuracy:  53.0%,  Validation Loss: 1.336\n",
      "Training Epoch 7 --- Training Accuracy:  60.0%, Validation Accuracy:  53.9%,  Validation Loss: 1.307\n",
      "Training Epoch 8 --- Training Accuracy:  58.0%, Validation Accuracy:  55.0%,  Validation Loss: 1.280\n",
      "Training Epoch 9 --- Training Accuracy:  60.0%, Validation Accuracy:  55.9%,  Validation Loss: 1.257\n",
      "Training Epoch 10 --- Training Accuracy:  60.0%, Validation Accuracy:  56.5%,  Validation Loss: 1.238\n",
      "Training Epoch 11 --- Training Accuracy:  62.0%, Validation Accuracy:  57.1%,  Validation Loss: 1.223\n",
      "Training Epoch 12 --- Training Accuracy:  68.0%, Validation Accuracy:  57.6%,  Validation Loss: 1.210\n",
      "Training Epoch 13 --- Training Accuracy:  68.0%, Validation Accuracy:  58.1%,  Validation Loss: 1.201\n",
      "Training Epoch 14 --- Training Accuracy:  70.0%, Validation Accuracy:  58.5%,  Validation Loss: 1.194\n",
      "Training Epoch 15 --- Training Accuracy:  72.0%, Validation Accuracy:  59.2%,  Validation Loss: 1.185\n",
      "Training Epoch 16 --- Training Accuracy:  74.0%, Validation Accuracy:  59.6%,  Validation Loss: 1.179\n",
      "Training Epoch 17 --- Training Accuracy:  74.0%, Validation Accuracy:  59.6%,  Validation Loss: 1.178\n",
      "Training Epoch 18 --- Training Accuracy:  74.0%, Validation Accuracy:  59.9%,  Validation Loss: 1.174\n",
      "Training Epoch 19 --- Training Accuracy:  74.0%, Validation Accuracy:  59.8%,  Validation Loss: 1.181\n",
      "Training Epoch 20 --- Training Accuracy:  74.0%, Validation Accuracy:  60.2%,  Validation Loss: 1.175\n",
      "Training Epoch 21 --- Training Accuracy:  74.0%, Validation Accuracy:  60.4%,  Validation Loss: 1.179\n",
      "Training Epoch 22 --- Training Accuracy:  76.0%, Validation Accuracy:  60.6%,  Validation Loss: 1.178\n",
      "Training Epoch 23 --- Training Accuracy:  76.0%, Validation Accuracy:  60.5%,  Validation Loss: 1.179\n",
      "Training Epoch 24 --- Training Accuracy:  78.0%, Validation Accuracy:  60.4%,  Validation Loss: 1.183\n",
      "Training Epoch 25 --- Training Accuracy:  78.0%, Validation Accuracy:  60.5%,  Validation Loss: 1.187\n",
      "Training Epoch 26 --- Training Accuracy:  78.0%, Validation Accuracy:  60.6%,  Validation Loss: 1.195\n",
      "Training Epoch 27 --- Training Accuracy:  76.0%, Validation Accuracy:  60.5%,  Validation Loss: 1.202\n",
      "Training Epoch 28 --- Training Accuracy:  74.0%, Validation Accuracy:  60.5%,  Validation Loss: 1.207\n",
      "Training Epoch 29 --- Training Accuracy:  80.0%, Validation Accuracy:  60.4%,  Validation Loss: 1.212\n",
      "Training Epoch 30 --- Training Accuracy:  78.0%, Validation Accuracy:  60.4%,  Validation Loss: 1.221\n",
      "Training Epoch 31 --- Training Accuracy:  80.0%, Validation Accuracy:  60.3%,  Validation Loss: 1.228\n",
      "Training Epoch 32 --- Training Accuracy:  78.0%, Validation Accuracy:  60.3%,  Validation Loss: 1.237\n",
      "Training Epoch 33 --- Training Accuracy:  78.0%, Validation Accuracy:  60.2%,  Validation Loss: 1.249\n",
      "Training Epoch 34 --- Training Accuracy:  84.0%, Validation Accuracy:  60.1%,  Validation Loss: 1.263\n",
      "Training Epoch 35 --- Training Accuracy:  84.0%, Validation Accuracy:  59.9%,  Validation Loss: 1.276\n",
      "Training Epoch 36 --- Training Accuracy:  80.0%, Validation Accuracy:  59.6%,  Validation Loss: 1.297\n",
      "Training Epoch 37 --- Training Accuracy:  80.0%, Validation Accuracy:  59.3%,  Validation Loss: 1.313\n",
      "Training Epoch 38 --- Training Accuracy:  80.0%, Validation Accuracy:  59.2%,  Validation Loss: 1.325\n",
      "Training Epoch 39 --- Training Accuracy:  80.0%, Validation Accuracy:  58.9%,  Validation Loss: 1.344\n",
      "Training Epoch 40 --- Training Accuracy:  82.0%, Validation Accuracy:  58.9%,  Validation Loss: 1.356\n",
      "Training Epoch 41 --- Training Accuracy:  82.0%, Validation Accuracy:  59.1%,  Validation Loss: 1.364\n",
      "Training Epoch 42 --- Training Accuracy:  82.0%, Validation Accuracy:  59.0%,  Validation Loss: 1.382\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-86a40db2c285>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mtotal_iterations\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mnum_iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m96000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-86a40db2c285>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(num_iteration)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_Train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_examples\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amitp\\computervisiontools\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amitp\\computervisiontools\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amitp\\computervisiontools\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amitp\\computervisiontools\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amitp\\computervisiontools\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_Train=DatasetHandler(train_Data,train_Labels)\n",
    "data_Val=DatasetHandler(val_data,val_label)\n",
    "def train (num_iteration):\n",
    "    global total_iterations\n",
    "    \n",
    "    for i in range(total_iterations,total_iterations+num_iteration):\n",
    "        \n",
    "        x_batch,y_true_batch=data_Train.next_batch(batch_size)\n",
    "      \n",
    "        #print(data_Val._index_in_epoch)\n",
    "        feed_dict_tr={x:x_batch,\n",
    "                      y_true:y_true_batch}\n",
    "        \n",
    "        \n",
    "        session.run(optimizer,feed_dict=feed_dict_tr)\n",
    "        \n",
    "        if i % int(data_Train._num_examples/batch_size) == 0:\n",
    "            epoch = int(i / int(data_Train._num_examples/batch_size))\n",
    "            x_valid_batch,y_valid_batch=data_Val.next_batch(val_label.shape[0])\n",
    "            feed_dict_val={x:x_valid_batch,\n",
    "                                y_true:y_valid_batch}\n",
    "            val_loss = session.run(cost, feed_dict=feed_dict_val)           \n",
    "            show_progress(epoch, feed_dict_tr, feed_dict_val, val_loss)\n",
    "    total_iterations+=num_iteration\n",
    "\n",
    "train(num_iteration=96000)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
